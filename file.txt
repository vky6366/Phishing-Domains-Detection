'''from flask import Flask, request, render_template, jsonify
from urllib.parse import urlparse
import socket
import tldextract
import pandas as pd
import pickle
from sklearn.preprocessing import LabelEncoder  # Assuming encoders were pickled
from itertools import groupby

# Load model and encoders (assuming they've been saved as pickle files)
with open("model.pkl", "rb") as f:
    model = pickle.load(f)
with open("url_encoder.pkl", "rb") as f:
    url_encoder = pickle.load(f)
with open("domain_encoder.pkl", "rb") as f:
    domain_encoder = pickle.load(f)
with open("tld_encoder.pkl", "rb") as f:
    tld_encoder = pickle.load(f)

app = Flask(__name__)

# Utility functions for feature extraction
def is_domain_ip(domain):
    try:
        socket.inet_aton(domain)
        return 1
    except socket.error:
        return 0

def char_continuation_rate(url):
    return sum(1 for _ in groupby(url)) / len(url) if url else 0

def url_char_prob(url):
    suspicious_chars = ['%', '$', '&', '@']
    count = sum(url.count(char) for char in suspicious_chars)
    return count / len(url) if url else 0

def obfuscation_ratio(url):
    obfuscated = url.count('%')
    return obfuscated / len(url) if url else 0

def is_valid_url(url):
    parsed = urlparse(url)
    return bool(parsed.scheme) and bool(parsed.netloc)

def extract_features_from_url(url):
    extracted = tldextract.extract(url)
    domain = extracted.domain + '.' + extracted.suffix if extracted.suffix else extracted.domain
    subdomain = extracted.subdomain
    url_length = len(url)
    domain_length = len(domain)
    tld_length = len(extracted.suffix)
    no_of_subdomain = subdomain.count('.') + 1 if subdomain else 0
    is_https = 1 if url.startswith('https') else 0

    # Use encoders
    encoded_url = url_encoder.transform([url])[0]
    encoded_domain = domain_encoder.transform([domain])[0]
    encoded_tld = tld_encoder.transform([extracted.suffix])[0]

    features = {
        'EncodedURL': encoded_url,
        'EncodedDomain': encoded_domain,
        'EncodedTLD': encoded_tld,
        'URLLength': url_length,
        'DomainLength': domain_length,
        'IsDomainIP': is_domain_ip(domain),
        'URLSimilarityIndex': 100.0,  # Placeholder
        'CharContinuationRate': char_continuation_rate(url),
        'TLDLegitimateProb': 0.5229071,  # Example static value
        'URLCharProb': url_char_prob(url),
        'TLDLength': tld_length,
        'NoOfSubDomain': no_of_subdomain,
        'NoOfObfuscatedChar': url.count('%'),
        'ObfuscationRatio': obfuscation_ratio(url),
        'NoOfLettersInURL': sum(c.isalpha() for c in url),
        'LetterRatioInURL': sum(c.isalpha() for c in url) / url_length if url_length > 0 else 0,
        'NoOfDegitsInURL': sum(c.isdigit() for c in url),
        'DegitRatioInURL': sum(c.isdigit() for c in url) / url_length if url_length > 0 else 0,
        'NoOfEqualsInURL': url.count('='),
        'NoOfQMarkInURL': url.count('?'),
        'NoOfAmpersandInURL': url.count('&'),
        'NoOfOtherSpecialCharsInURL': sum(not c.isalnum() and not c.isspace() for c in url),
        'SpacialCharRatioInURL': sum(not c.isalnum() and not c.isspace() for c in url) / url_length if url_length > 0 else 0,
        'IsHTTPS': is_https
    }

    feature_order = [
        'EncodedURL', 'EncodedDomain', 'EncodedTLD', 'URLLength', 'DomainLength', 'IsDomainIP',
        'URLSimilarityIndex', 'CharContinuationRate', 'TLDLegitimateProb', 'URLCharProb',
        'TLDLength', 'NoOfSubDomain', 'NoOfObfuscatedChar', 'ObfuscationRatio', 'NoOfLettersInURL',
        'LetterRatioInURL', 'NoOfDegitsInURL', 'DegitRatioInURL', 'NoOfEqualsInURL',
        'NoOfQMarkInURL', 'NoOfAmpersandInURL', 'NoOfOtherSpecialCharsInURL',
        'SpacialCharRatioInURL', 'IsHTTPS'
    ]
    
    return pd.DataFrame([features], columns=feature_order)

@app.route('/predict', methods=['POST'])
def predict():
    url = request.form.get("url").strip()
    if not url:
        return jsonify({"error": "Please enter a URL."})
    if not is_valid_url(url):
        return jsonify({"error": "Invalid URL format."})

    try:
        features = extract_features_from_url(url)
    except ValueError:
        result = "Not Phishing" if url.startswith('https') else "Phishing"
        return jsonify({"result": result})

    prediction = model.predict(features)
    result = "Phishing" if prediction[0] == 1 else "Not Phishing"
    return jsonify({"result": result})

if __name__ == '__main__':
    app.run(debug=True)

from flask import *
#from app_server import Flask, request, jsonify
import joblib
import socket
from urllib.parse import urlparse
import tldextract
import pandas as pd
from itertools import groupby
#from flask_cors import CORS

import pickle

# Load the model and encoders using pickle
with open(r"D:\PyHack-PyAITM-PyHack04-main\PyHack-PyAITM-PyHack04-main\Final Project\LogisticReg_model.pkl", 'rb') as f:
    model = pickle.load(f)

with open(r"D:\PyHack-PyAITM-PyHack04-main\PyHack-PyAITM-PyHack04-main\Final Project\url_encoder.pkl", 'rb') as f:
    url_encoder = pickle.load(f)

with open(r"D:\PyHack-PyAITM-PyHack04-main\PyHack-PyAITM-PyHack04-main\Final Project\domain_encoder.pkl", 'rb') as f:
    domain_encoder = pickle.load(f)

with open(r"D:\PyHack-PyAITM-PyHack04-main\PyHack-PyAITM-PyHack04-main\Final Project\tld_encoder.pkl", 'rb') as f:
    tld_encoder = pickle.load(f)

#model = joblib.load(r"D:\PyHack-PyAITM-PyHack04-main\PyHack-PyAITM-PyHack04-main\Final Project\decisionTree_model.pkl")
#url_encoder = joblib.load(r"D:\PyHack-PyAITM-PyHack04-main\PyHack-PyAITM-PyHack04-main\Final Project\url_encoder.pkl")
#domain_encoder = joblib.load(r"D:\PyHack-PyAITM-PyHack04-main\PyHack-PyAITM-PyHack04-main\Final Project\domain_encoder.pkl")
#tld_encoder = joblib.load(r"D:\PyHack-PyAITM-PyHack04-main\PyHack-PyAITM-PyHack04-main\Final Project\tld_encoder.pkl")

app = Flask(__name__)
#CORS(app)

def is_domain_ip(domain):
        try:
            socket.inet_aton(domain)
            return 1
        except socket.error:
            return 0

def char_continuation_rate(url):
    from itertools import groupby
    return sum(1 for _ in groupby(url)) / len(url) if url else 0

def url_char_prob(url):
    suspicious_chars = ['%', '$', '&', '@']
    count = sum(url.count(char) for char in suspicious_chars)
    return count / len(url) if url else 0

@staticmethod
def obfuscation_ratio(url):
    obfuscated = url.count('%')  # Simple count of URL-encoded characters
    return obfuscated / len(url) if url else 0

@staticmethod
def is_valid_url(url):
    parsed = urlparse(url)
    return bool(parsed.scheme) and bool(parsed.netloc)

def extract_features_from_url(url):
    extracted = tldextract.extract(url)
    domain = extracted.domain + '.' + extracted.suffix if extracted.suffix else extracted.domain
    subdomain = extracted.subdomain
    url_length = len(url)
    domain_length = len(domain)
    tld_length = len(extracted.suffix)
    no_of_subdomain = subdomain.count('.') + 1 if subdomain else 0
    is_https = 1 if url.startswith('https') else 0
    # Use the encoders to transform data
    encoded_url = url_encoder.transform([url])[0]
    encoded_domain = domain_encoder.transform([domain])[0]
    encoded_tld = tld_encoder.transform([extracted.suffix])[0]
    features = {
        'EncodedURL': encoded_url,
        'EncodedDomain': encoded_domain,
        'EncodedTLD': encoded_tld,
        'URLLength': url_length,
        'DomainLength': domain_length,
        'IsDomainIP': is_domain_ip(domain),
        'URLSimilarityIndex': 100.0,  # Placeholder
        'CharContinuationRate': char_continuation_rate(url),
        'TLDLegitimateProb': 0.5229071,  # Example static value
        'URLCharProb': url_char_prob(url),
        'TLDLength': tld_length,
        'NoOfSubDomain': no_of_subdomain,
        'NoOfObfuscatedChar': url.count('%'),
        'ObfuscationRatio': obfuscation_ratio(url),
        'NoOfLettersInURL': sum(c.isalpha() for c in url),
        'LetterRatioInURL': sum(c.isalpha() for c in url) / url_length if url_length > 0 else 0,
        'NoOfDegitsInURL': sum(c.isdigit() for c in url),
        'DegitRatioInURL': sum(c.isdigit() for c in url) / url_length if url_length > 0 else 0,
        'NoOfEqualsInURL': url.count('='),
        'NoOfQMarkInURL': url.count('?'),
        'NoOfAmpersandInURL': url.count('&'),
        'NoOfOtherSpecialCharsInURL': sum(not c.isalnum() and not c.isspace() for c in url),
        'SpacialCharRatioInURL': sum(not c.isalnum() and not c.isspace() for c in url) / url_length if url_length > 0 else 0,
        'IsHTTPS': is_https
    }
    # Ensure all features used during model training are generated here
    feature_order = ['EncodedURL', 'EncodedDomain', 'EncodedTLD', 'URLLength', 'DomainLength', 'IsDomainIP', 
                     'URLSimilarityIndex', 'CharContinuationRate', 'TLDLegitimateProb', 'URLCharProb', 
                     'TLDLength', 'NoOfSubDomain', 'NoOfObfuscatedChar', 'ObfuscationRatio', 'NoOfLettersInURL', 
                     'LetterRatioInURL', 'NoOfDegitsInURL', 'DegitRatioInURL', 'NoOfEqualsInURL', 
                     'NoOfQMarkInURL', 'NoOfAmpersandInURL', 'NoOfOtherSpecialCharsInURL', 
                     'SpacialCharRatioInURL', 'IsHTTPS']
    return pd.DataFrame([features], columns=feature_order)


@app.route('/predict', methods=['POST'])
def predict_phishing():
    data = request.form['url']
    url = extract_features_from_url(data)
    if not url:
        return jsonify({"error": "Please provide a URL."}), 400

    if not is_valid_url(url):
        return jsonify({"error": "Invalid URL format."}), 400
    try:
        features = extract_features_from_url(data)
    except ValueError:
        result = "Not Phishing" if url.startswith('https') else "Phishing"
        return jsonify({"prediction": result})
    prediction = model.predict(features)
    result = "Phishing" if prediction[0] == 1 else "Not Phishing"
    return jsonify({"prediction": result})

if __name__ == '__main__':
    app.run(debug=True)'''
